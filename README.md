# Autonomy-of-L4-Trucking
This is the summary on public resources, such as industry solutions, academic papers and youtube talks. I collected them during my work and hope the sharing can help you:-)

## 1. Main Player
- Aurora, [intro](https://www.youtube.com/watch?v=EOhR_RIKmEI)
- TuSimple, [intro](https://www.youtube.com/watch?v=zM7oGhEq2Jo)
- Torc.ai, [homepage](https://torc.ai)
- Embark, [homepage](https://embarktrucks.com)
- Waymo, [intro](https://www.youtube.com/watch?v=oJ96bgmSaW0)

Other L4 related, such as RoboTaxi:
- Cruise,  [intro](https://www.youtube.com/watch?v=uJWN0K26NxQ)

## 2. Main Researcher institution
- Prof. Raquel Urtasun, http://www.cs.toronto.edu/~urtasun/
- Bin Yang, Waabi, http://www.cs.toronto.edu/~byang/

## 3. Algorithm of Autonomy
#### Perception
- FIERY: Future Instance Prediction in Bird's-Eye View from Surround Monocular Cameras, [link](https://arxiv.org/abs/2104.10490)
- RadarNet: Exploiting Radar for Robust Perception of Dynamic Objects, [link](https://arxiv.org/pdf/2007.14366.pdf)
- End-to-End Perception and Prediction with Tracking in the Loop, [link](https://arxiv.org/pdf/2005.14711.pdf)
- Fast and furious: Real time end-to-end 3d detection, tracking and motion forecasting with a single convolutional net, 2018 [link](https://openaccess.thecvf.com/content_cvpr_2018/papers/Luo_Fast_and_Furious_CVPR_2018_paper.pdf)
- 
#### Prediction
- MultiPath++, https://arxiv.org/abs/1910.05449

#### Motion Planning
- Overview (zhihu), https://zhuanlan.zhihu.com/p/59089908

#### Vision Lidar (Vidar)
- MobileEye, Stereo Camera, [link](https://s21.q4cdn.com/600692695/files/doc_presentations/2020/1/Mobileye-CES-2020-presentation.pdf)
- Waymo, Multiple Monocular Camera, [link](https://youtu.be/rbDuK5e1bWw?t=555)
- Tesla, Multiple Monocular Cameras, [link](https://www.youtube.com/watch?v=NSDTZQdo6H8)

#### Offline Perception/Auto-labeling
- Offboard 3D Object Detection from Point Cloud Sequences, 2021 [link](https://arxiv.org/abs/2103.05073)
- Auto4D: Learning to Label 4D Objects from Sequential Point Clouds, 2021 [link](https://arxiv.org/pdf/2101.06586.pdf)

## 4. Simulation
#### Carla, https://github.com/carla-simulator/carla
#### LGSVL, https://github.com/lgsvl/simulator
#### Research paper
- SurfelGAN, [link](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_SurfelGAN_Synthesizing_Realistic_Sensor_Data_for_Autonomous_Driving_CVPR_2020_paper.pdf)
- GeoSim, [link](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_GeoSim_Realistic_Video_Simulation_via_Geometry-Aware_Composition_for_Self-Driving_CVPR_2021_paper.pdf)
- Towards Optimal Strategies for Training Self-Driving Perception Models in Simulation, [link](https://arxiv.org/pdf/2111.07971.pdf)

## 5. OpenSource code/dataset
#### Code implementation
- Camera based dense object tracking : https://github.com/SysCV/qd-3dt

#### Dataset
- https://www.siasearch.io/blog/best-open-source-autonomous-driving-datasets

## 6. Main Challenge
